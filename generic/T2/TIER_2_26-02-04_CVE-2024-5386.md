## Executive Summary

CVE-2024-5386 is a critical account-hijacking vulnerability in `lunary-ai/lunary` 1.2.2, arising from a password reset token leak. A low-privilege “viewer” user can trigger a backend flow that returns a valid password reset token in the `recoveryToken` field, and then use this token to reset another user’s password without authorisation. This effectively enables lateral privilege escalation within a Lunary deployment, allowing an attacker to take over higher-privilege accounts and gain access to projects, secrets, and model telemetry.

While exploitation requires an existing low-privilege account on the Lunary instance (and so is not completely unauthenticated), the flaw is easily weaponised in multi-tenant SaaS or shared deployments where onboarding new viewers is common. The impact of escalating from viewer to admin or owner is substantial: attackers can exfiltrate experiment metadata, API keys, and model configurations, and may gain leverage over downstream applications. In the Kill Chain Economics framework, this earns a Tier 2 rating: high value but barriered by the need for an initial Lunary account.

Assessment Tier: TIER 2 (High Value but Barriered – Viewer-to-Admin Account Hijacking)
Full analysis: https://github.com/alan-turing-institute/cyber-threat-observatory/blob/main/generic/T2/TIER_2_26-02-04_CVE-2024-5386.md
Rationale:
- Password reset tokens are exposed to low-privilege “viewer” accounts, enabling them to reset other users’ passwords
- Exploitation requires only viewer-level access; no special privileges, social engineering, or complex exploitation
- Impact is high: complete account takeover, including admins, within a Lunary instance
- Barriers (need for account plus Lunary-specific context) keep this from Tier 1, but it is clearly a high-priority privilege-escalation flaw
Attractiveness Score: HIGH
DPI Relevance: General Infrastructure (Observability / AI Operations Tooling)
Vulners reference: https://vulners.com/cve/CVE-2024-5386

---

## In-Depth Analysis

### 1. Software and Deployment Context

- **Software:** Lunary (`lunary-ai/lunary`) 1.2.2 – observability and analytics tooling for LLM/AI systems
- **Role:** Provides dashboards, telemetry, and configuration surfaces for monitoring and tuning AI applications
- **Typical deployment:**
  - Self-hosted or SaaS deployments integrated with application backends
  - Users with varying roles: viewer, editor, admin/owner

The vulnerability directly targets the authentication and account recovery logic, not the AI-specific features.

### 2. Vulnerability Mechanics

- **Root cause:** Excessive trust in lower-privilege users and insecure password-reset logic:
  - A viewer can issue a specific request that triggers backend password-reset flows.
  - The backend responds with a `recoveryToken` in the response body, leaking the secret required to reset another user’s password.
- **Exploit path (per advisory):**
  1. Viewer logs into Lunary and sends a crafted request to the password-reset or account-recovery endpoint.
  2. The server responds with a `recoveryToken` associated with a target account.
  3. The attacker uses that token to complete the password-reset flow for the victim account.
  4. They log in as the victim (e.g. admin or owner) with a new password.
- **Impact:**
  - Complete takeover of higher-privilege accounts
  - Access to projects, logs, model prompts, and stored secrets
  - Ability to modify configurations or pipeline hooks that influence production systems

This is a textbook privilege-escalation via insecure direct object reference in the account recovery flow.

### 3. Kill Chain Utility Assessment

**Initial access vs post-compromise**

- CVE-2024-5386 requires a Lunary account but then enables **intra-tenant escalation**:
  - In open or semi-open deployments (e.g. where inviting viewers is common), an adversary can often obtain a viewer account through benign channels.
  - In more closed environments, an attacker may first compromise a low-privilege account via phishing or credential stuffing.

**Attacker gain**

- Once exploited, the attacker can:
  - Escalate from viewer to administrator/owner within a Lunary instance.
  - Steal credentials, API keys, and telemetry data associated with LLM/AI workloads.
  - Introduce malicious changes into observability or evaluation pipelines that alter trust decisions or mask attacker activity.

**Barriers and reliability**

- Barriers:
  - Requires at least viewer-level authentication.
  - Requires some awareness of the vulnerable endpoint and response fields.
- Reliability:
  - The process is deterministic and easily scripted using standard HTTP tooling.

From a WAA perspective this is a classic high-value but barriered escalation vector, meriting **Tier 2**.

### 4. Organisational Context and DPI Relevance

- **AI-intensive environments:** Organisations integrating Lunary deeply into AI operations workflows are particularly exposed:
  - Account hijacking can undermine the integrity of evaluation metrics and guardrail behaviour.
  - Compromised Lunary instances can leak prompts, responses, and secret keys that feed downstream systems.
- **DPI context:** While Lunary is not DPI-specific, misconfiguration or compromise within DPI-related AI pipelines can have outsized downstream effects.

Thus this vulnerability should be addressed promptly within general infrastructure risk management.

### 5. Recommended Mitigations

- **Upgrade:**
  - Update Lunary to version **1.2.14** or later, where the password-reset logic is fixed and recovery tokens are not exposed to low-privilege users.
- **Account and token hygiene:**
  - Invalidate any outstanding recovery tokens issued prior to patching.
  - Review user role assignments, focusing on viewers who may not need access.
  - Force password resets for high-privilege accounts if evidence of exploitation exists.
- **Defence-in-depth:**
  - Log and alert on anomalous password-reset flows, particularly those originating from lower-privilege users.
  - Consider rate limiting and additional verification for password-reset workflows.

Applying these mitigations reduces both the likelihood and the payoff of exploiting CVE-2024-5386 in modern AI observability stacks.

